# Analysis of Multilingual Automatic Speech Recognition Approaches

**BSc Thesis** | Budapest University of Technology and Economics  
**Author**: Munkhchimeg Sergelen  
**Supervisor**: Dr. Mihajlik PÃ©ter  
**Department**: Department of Telecommunications and Media Informatics  
**Date**: November 2025

---

## ğŸ“‹ Abstract

This thesis evaluates two multilingual ASR approaches: **LIDâ†’ASR** (automatic language identification followed by transcription) versus **language-hinted ASR** (where language is explicitly provided). Through 312 controlled experiments across 4 languages (Spanish, French, Hungarian, Mongolian), we discovered that:

- ğŸ¯ **Whisper's LID achieves 99.31% accuracy** - production-ready performance
- âš¡ **LIDâ†’ASR is 2.76Ã— faster** than language-hinted mode (surprising!)
- ğŸ‡²ğŸ‡³ **Mongolian processes 10-30Ã— slower** than other languages (critical inequality)
- ğŸ“Š **Model size scaling**: 6Ã— speed difference between tiny and small models
- ğŸ† **Whisper dominates** multilingual scenarios over language-specific models

---

## ğŸ”¬ Research Questions

1. **How accurate is automatic language identification for multilingual ASR?**  
   â†’ 99.31% - near-perfect across all tested languages

2. **How does processing efficiency compare between LIDâ†’ASR and language-hinted approaches?**  
   â†’ LIDâ†’ASR is 2.76Ã— faster (6.80s vs 18.78s average)

3. **How do different Whisper model sizes compare in processing efficiency?**  
   â†’ 6Ã— speed difference (tiny: 2.28s, small: 13.80s)

4. **How does multilingual ASR performance vary across languages?**  
   â†’ Mongolian 10-30Ã— slower than Spanish/French/Hungarian

5. **How do different ASR systems compare for multilingual deployment?**  
   â†’ Whisper better for multilingual use (built-in LID, broader coverage)

---

## ğŸš€ Quick Start

### Prerequisites

```bash
# Create conda environment
conda create -n asr-env python=3.10
conda activate asr-env

# Install dependencies
pip install faster-whisper transformers torch librosa soundfile numpy pandas matplotlib seaborn
```

### Running Evaluations

```bash
# 1. Language-Hinted Mode (168 experiments)
./scripts/run_full_evaluation.sh

# 2. LIDâ†’ASR Mode (144 experiments)
./scripts/run_lid_evaluation.sh

# 3. Analyze Results
python scripts/analyze_results.py
python scripts/analyze_lid_accuracy.py
python scripts/compare_lid_vs_hinted.py

# 4. Generate Plots
python scripts/create_plots.py
```

---

## ğŸ“Š Key Results

### Language Identification Accuracy

| Language   | Accuracy | Samples | Errors |
|------------|----------|---------|--------|
| Spanish    | 100.0%   | 36      | 0      |
| French     | 100.0%   | 36      | 0      |
| Hungarian  | 97.22%   | 36      | 1      |
| Mongolian  | 100.0%   | 36      | 0      |
| **Overall** | **99.31%** | **144** | **1** |

### Processing Time Comparison

| Mode                 | Mean (s) | Speedup |
|----------------------|----------|---------|
| LIDâ†’ASR             | 6.80     | 2.76Ã—   |
| Language-Hinted     | 18.78    | 1.0Ã—    |

### Model Size Impact

| Model  | Parameters | Mean Time (s) | Speed vs Tiny |
|--------|------------|---------------|---------------|
| Tiny   | 39M        | 2.28          | 1.0Ã—          |
| Base   | 74M        | 4.31          | 1.89Ã—         |
| Small  | 244M       | 13.80         | 6.05Ã—         |

### Language-Specific Performance

| Language   | Mean (s) | Std Dev (s) | Slowdown vs Spanish |
|------------|----------|-------------|---------------------|
| Spanish    | 2.56     | 1.80        | 1.0Ã—                |
| French     | 2.80     | 1.97        | 1.09Ã—               |
| Hungarian  | 3.27     | 2.26        | 1.28Ã—               |
| **Mongolian** | **30.56** | **32.02** | **11.9Ã—** âš ï¸ |

---

## ğŸ“ Repository Structure

```
thesis-asr/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ wav/                          # Audio test files (not included)
â”‚       â”œâ”€â”€ es/                       # Spanish samples
â”‚       â”œâ”€â”€ fr/                       # French samples
â”‚       â”œâ”€â”€ hu/                       # Hungarian samples
â”‚       â””â”€â”€ mn/                       # Mongolian samples
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ thesis_materials/             # Thesis chapters
â”‚       â”œâ”€â”€ 00_abstract.md
â”‚       â”œâ”€â”€ 01_introduction.md
â”‚       â”œâ”€â”€ 02_background.md
â”‚       â”œâ”€â”€ 01_methods_hardware.md
â”‚       â”œâ”€â”€ 02_methods_systems.md
â”‚       â”œâ”€â”€ 03_results.md
â”‚       â”œâ”€â”€ 05_discussion.md
â”‚       â”œâ”€â”€ 06_conclusions.md
â”‚       â”œâ”€â”€ 10_bibliography.md
â”‚       â””â”€â”€ figures/                  # Generated plots
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_whisper.py                # Whisper inference
â”‚   â”œâ”€â”€ run_wav2vec2.py               # Wav2Vec2 inference
â”‚   â”œâ”€â”€ run_full_evaluation.sh        # Hinted mode evaluation
â”‚   â”œâ”€â”€ run_lid_evaluation.sh         # LID mode evaluation
â”‚   â”œâ”€â”€ analyze_results.py            # Statistical analysis
â”‚   â”œâ”€â”€ analyze_lid_accuracy.py       # LID accuracy metrics
â”‚   â”œâ”€â”€ compare_lid_vs_hinted.py      # Mode comparison
â”‚   â””â”€â”€ create_plots.py               # Generate figures
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ transcripts/                  # Raw transcription outputs
â”‚   â”‚   â”œâ”€â”€ hinted/                   # Language-hinted results
â”‚   â”‚   â””â”€â”€ lid2asr/                  # LIDâ†’ASR results
â”‚   â””â”€â”€ analysis/                     # Analysis outputs
â”‚       â”œâ”€â”€ summary.txt
â”‚       â”œâ”€â”€ mode_comparison_report.txt
â”‚       â”œâ”€â”€ lid_accuracy_summary.txt
â”‚       â””â”€â”€ *.csv                     # Detailed statistics
â””â”€â”€ README.md                         # This file
```

---

## ğŸ”„ Reproducing Results

### Step 1: Obtain Test Data

Download Mozilla Common Voice v11.0 test set:
```bash
# Spanish
wget https://mozilla-common-voice-datasets.s3.amazonaws.com/cv-corpus-11.0-2022-09-21/cv-corpus-11.0-2022-09-21-es.tar.gz

# French, Hungarian, Mongolian (similar URLs)
```

Extract 12 samples per language to `data/wav/{lang}/`

### Step 2: Run Evaluations

```bash
# Activate environment
conda activate asr-env

# Run hinted mode (3 hours)
./scripts/run_full_evaluation.sh

# Run LID mode (2-3 hours)
./scripts/run_lid_evaluation.sh
```

### Step 3: Analyze & Plot

```bash
# Generate all analysis files
python scripts/analyze_results.py
python scripts/analyze_lid_accuracy.py
python scripts/compare_lid_vs_hinted.py
python scripts/create_plots.py
```

Results will be in `results/analysis/` and `docs/thesis_materials/figures/`

---

## ğŸ“Š Generated Outputs

### Analysis Files

- `results/analysis/summary.txt` - Quick overview
- `results/analysis/overall_statistics.csv` - Aggregated stats
- `results/analysis/whisper_model_comparison.csv` - Model scaling
- `results/analysis/language_analysis.csv` - Language performance
- `results/analysis/lid_accuracy_summary.txt` - LID metrics
- `results/analysis/lid_confusion_matrix.csv` - LID errors
- `results/analysis/mode_comparison_report.txt` - **Core finding!**

### Figures

- `whisper_model_comparison.png/pdf` - Model size comparison
- `system_comparison.png/pdf` - Whisper vs Wav2Vec2
- `language_comparison.png/pdf` - Performance by language
- `processing_time_dist.png/pdf` - Processing time distribution
- `summary_table.png` - Summary statistics table

---

## ğŸ¯ Key Contributions

1. **First systematic evaluation of Whisper's LID capability** (99.31% accuracy)
2. **Discovery that LIDâ†’ASR is faster than hinted mode** (2.76Ã— speedup)
3. **Quantification of low-resource language performance gap** (Mongolian 10-30Ã— slower)
4. **Deployment-focused evaluation methodology** (efficiency metrics, not just WER)
5. **Fully reproducible framework** with open-source scripts

---

## ğŸ’¡ Practical Recommendations

### For Practitioners:

âœ… **Use LIDâ†’ASR by default** - Faster AND 99% accurate  
âœ… **Choose model size based on constraints**:
  - Real-time applications: Whisper-tiny (2.28s avg)
  - Batch processing: Whisper-small (13.80s avg)
  - Balanced: Whisper-base (4.31s avg)

âš ï¸ **Avoid Whisper-small for low-resource languages** - Use tiny/base instead  
âš ï¸ **Test all target languages before deployment** - Performance varies 10-30Ã—  
âš ï¸ **Implement timeout mechanisms** - Protect against 151s worst-case slowdowns

### For Researchers:

âœ… **Evaluate low-resource languages explicitly** - Don't assume universal models work universally  
âœ… **Report efficiency metrics** - WER alone insufficient for deployment  
âœ… **Test LID accuracy** - Don't assume it works, measure it  
âœ… **Document worst-case behavior** - Report max latency, not just mean

---

## âš ï¸ Limitations

- **No WER/CER metrics**: Lack of reference transcripts (future work)
- **CPU-only evaluation**: GPU failed due to cuDNN compatibility
- **Limited audio characteristics**: Only ~10-15s clean clips
- **Small sample size**: 12 samples per language per model
- **Limited language coverage**: 4 of 99 Whisper-supported languages

All limitations acknowledged and discussed in thesis.

---

## ğŸ”® Future Work

### Immediate Extensions:
- Add WER/CER evaluation with reference transcripts
- Resolve GPU cuDNN issues for GPU evaluation
- Test broader language coverage (10-20 languages)
- Evaluate varying audio lengths (5s, 15s, 60s+)

### Advanced Research:
- Root cause analysis of Mongolian slowdown
- Investigation of LID speed advantage mechanism
- Code-switching evaluation
- Long-form audio strategies
- Low-resource language optimization
- Noisy audio robustness testing

---

## ğŸ“š Citation

If you use this work, please cite:

```bibtex
@mastersthesis{sergelen2025multilingual,
  title={Analysis of Multilingual Automatic Speech Recognition Approaches},
  author={Sergelen, Munkhchimeg},
  year={2025},
  school={Budapest University of Technology and Economics},
  type={Bachelor's Thesis},
  supervisor={Dr. Mihajlik PÃ©ter}
}
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see LICENSE file for details.

---

## ğŸ™ Acknowledgments

- **Dr. Mihajlik PÃ©ter** - Thesis supervisor
- **OpenAI** - Whisper model
- **Facebook AI** - Wav2Vec2-XLSR-53 model
- **Mozilla** - Common Voice dataset
- **Budapest University of Technology and Economics** - Resources and support

---

## ğŸ“§ Contact

**Munkhchimeg Sergelen**  
Budapest University of Technology and Economics  
Department of Telecommunications and Media Informatics

For questions about this thesis, please contact via GitHub issues.

---

## ğŸ“Š Thesis Status

- âœ… **312 experiments completed** (100% success rate)
- âœ… **All 5 research questions answered**
- âœ… **2 surprising discoveries** (LID speed, Mongolian slowdown)
- âœ… **51 pages written**
- âœ… **5 publication-quality plots generated**
- âœ… **Ready for submission** (November 2025)

---

**Last Updated**: November 12, 2025  
**Thesis Defense**: TBD  
**Status**: 95% Complete - Polishing Phase
