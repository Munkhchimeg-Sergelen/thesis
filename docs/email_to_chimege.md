# Email to Chimege - Mongolian ASR Research Inquiry

---

**Subject:** Academic Research Inquiry: Mongolian ASR Performance Optimization

---

Dear Chimege Team,

My name is Munkhchimeg Sergelen, and I am a graduate student conducting research on multilingual automatic speech recognition (ASR) systems, with a particular focus on low-resource languages including Mongolian.

I recently came across your excellent work at Chimege (https://chimege.com) and was impressed by your suite of Mongolian language technology products. Your expertise in this area is particularly relevant to my current research.

**My Research Context:**

I am conducting a comparative performance analysis of state-of-the-art ASR models (Whisper, OmniLingual ASR) across four languages: Mongolian, Hungarian, Spanish, and French. My preliminary findings reveal a significant performance gap specifically for Mongolian:

- Whisper-small shows extreme processing slowdown on Mongolian audio (RTF ~37) compared to other languages (RTF 0.5-1.8)
- This is 74× slower than its performance on Spanish
- OmniLingual models maintain consistent performance across all languages

This finding suggests unique challenges in Mongolian ASR that I would like to investigate further for my thesis.

**Questions for Academic Collaboration:**

If you would be willing to share insights for academic/research purposes, I would be very grateful to learn about:

1. **Model Architecture:** What ASR approach/models does Chimege use for Mongolian speech recognition? (e.g., traditional models, transformer-based, CTC, RNN-T)

2. **Language-Specific Optimizations:** Have you implemented specific optimizations for Mongolian's unique characteristics (Cyrillic script, agglutinative morphology, phonetic features)?

3. **Performance Metrics:** What accuracy levels (WER/CER) do you typically achieve for Mongolian ASR? How does this compare to your experience with other languages?

4. **Training Data:** What size and type of Mongolian speech datasets have you found most effective? (I understand proprietary details may not be shareable)

5. **Known Challenges:** What were the main technical challenges you encountered when building Mongolian ASR, and how did you address them?

6. **Comparative Analysis:** Have you benchmarked your system against international models like Whisper or Wav2Vec2? If so, what were your observations?

**Potential Collaboration:**

If appropriate, I would be honored to:
- Cite Chimege's insights in my thesis
- Acknowledge your contributions to Mongolian language technology research
- Share my comparative findings if they would be useful for your work
- Explore potential academic collaboration opportunities

I fully understand if some technical details are proprietary. Any insights you can share for academic purposes would be invaluable for advancing research in low-resource language ASR.

**My Background:**
- Graduate student in [Your University/Program]
- Research focus: Multilingual ASR performance analysis
- Dataset: Common Voice multilingual test sets (1,000 samples per language)
- Comparative models: Whisper, OmniLingual ASR (CTC and LLM variants)

Thank you very much for considering my request. I deeply appreciate the important work Chimege is doing for Mongolian language technology, and I hope my research can contribute to broader understanding of ASR challenges for low-resource languages.

I would be happy to schedule a brief call or exchange emails at your convenience.

Best regards,

Munkhchimeg Sergelen
[Your Email]
[Your University/Institution]
[Your LinkedIn/Research Profile - if applicable]

---

**Attachments (optional):**
- Brief research summary or preliminary findings
- Plot showing Mongolian performance gap

---

## Alternative Shorter Version:

**Subject:** Academic Inquiry: Mongolian ASR Performance Research

Dear Chimege Team,

I am Munkhchimeg Sergelen, a graduate student researching multilingual ASR performance. I discovered your work at Chimege and was very impressed.

My thesis compares Whisper and OmniLingual ASR across Mongolian, Hungarian, Spanish, and French. I found that Whisper performs 74× slower on Mongolian than Spanish (RTF 37 vs 0.5), while OmniLingual maintains consistent speed across all languages.

For my academic research, I would greatly appreciate any insights you could share about:
- Your approach to Mongolian ASR optimization
- Challenges you've encountered with Mongolian speech processing
- Typical WER/CER performance you achieve
- How you handle Mongolian's unique linguistic features

I understand some details may be proprietary. Any guidance for academic purposes would be invaluable for advancing low-resource language ASR research.

Thank you for your consideration and for your important work in Mongolian language technology.

Best regards,
Munkhchimeg Sergelen
[Contact details]
